[
  {
    "authors": [
      "Xiaoran Xu"
    ],
    "categories": null,
    "content": "I would rather see intelligence as an ability to grow in knowledge and wisdom than as a product made by genius engineers that is ready for sale. If we really wish AI to own the same intellectual ability as us, we should be aware of the process of how we develop our intelligence. We, as intelligent beings, are born as a blank sheet of paper. To acquire intellectual growing, children need to learn from the environment, parents, teachers, friends and even opponents except engineers, that is, children need to learn from interaction with other humans. From this point of view, changing children with AI, I am curious about what roles humans could play in the long and continuous process of growing AI except acting as engineers and scientists to built AI. Therefore, to grow AI may be a much more challenging task than to build one, requiring all humankind involved to become an indispensible part of the whole AI learning ecosystem.\nI can think of several roles that humans can take listed as follows:\n Teachers. This role should provide clear and correct answers for AI as in supervised learning. The answers could be a right final outcome to be predicted such as labels, or a sequence of correct actions that let AI be able to mimic step by step. More flexibly, instead of final or all-the-way supervising, teachers can pick the critical moments to give supervison more efficiently. Masters. Unlike teachers, masters do not have to hold enough domain knowledge to teach machines exactly what to do. Instead, they should be able to sense whether an action or a produced result is acceptable or not, and provide appropriate encouragement or rewards as well as warnings or penalties as in reinforcement learning. This kind of relationship between humans and machines is like the one between masters and pets. Compared with teachers, the master role requires less human\u0026rsquo;s effort, but with more people involved in the direction interaction with machines, it can release the burden on AI engineers and provide much richer guidence from the human society. Opponents or competitors. From its literal meaning, this role plays against machines, a sort of adversarial training to force machines to make progress on its own. Playing chess or go between humans and machines belongs to this domain, but it demands all-the-way sparring and may consume too much time from humans. Another type of opponents is a trouble maker who can creat obstacles for machines from time to time. Parteners or cooperators. Contrary to opponents, this role requires huamns to work with or aid machines to achieve some goal. This sort of aid is incomparable with that of teachers or masters but no more than a communication channel or a helpful behavior, as human parteners are also a game player similar to machines and may even know little about this world. Even so, human parteners can still give extra observed information to machines and watch how machines react, which provides an opportunity for both to communicate with and learn from each other. Agent builders. This role is actually played by engineers. An agent builder can decide how to design and assemble an AI machine, such as what types of sensors it has, what actions it can take, and how deep its neural network can go. World builders. This role acts as a super administrator who owns the hightest priviledge to add, remove and modify every detail in this world, and to design new sceniors and set up new tasks to train machines.  ",
    "date": 1542038400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1542038400,
    "objectID": "ab1e99735cb0776687a6728f9b9fa913",
    "permalink": "https://www.xiaoranxu.com/thinking/about-human-roles/",
    "publishdate": "2018-11-13T00:00:00+08:00",
    "relpermalink": "/thinking/about-human-roles/",
    "section": "thinking",
    "summary": "I would rather see intelligence as an ability to grow in knowledge and wisdom than as a product made by genius engineers that is ready for sale. If we really wish AI to own the same intellectual ability as us, we should be aware of the process of how we develop our intelligence. We, as intelligent beings, are born as a blank sheet of paper. To acquire intellectual growing, children need to learn from the environment, parents, teachers, friends and even opponents except engineers, that is, children need to learn from interaction with other humans. From this point of view, changing children with AI, I am curious about what roles humans could play in the long and continuous process of growing AI except acting as engineers and scientists to built AI ...",
    "tags": [
      "Human Roles",
      "Growing AI"
    ],
    "title": "Human Roles in Growing AI",
    "type": "thinking"
  },
  {
    "authors": [
      "Xiaoran Xu"
    ],
    "categories": null,
    "content": "Current machine learning and deep learning models are trained by tasks that come mostly from real-life applications with practical purposes. Few tasks are designed specially and systematically for the purpose of studying pure intelligence. Why is this very important? Much efforts today in the AI community have been put on designing AI models that are AI\u0026rsquo;s brains, whereas less studies are concentrated on how to design and organize a series of tasks that can help AI grow.\nOn the contrary, for human intelligence, we do not put too much thoughts on how our brains are built, whereas we would emphasize the importance of education, create educational environemnt and develop curricula as good as possible to make sure our children\u0026rsquo;s intelligence would grow from a blank canvas into a stunning piece. In this regard, studies on education should be treated as part of the whole ecosystem of AI research. The stories of feral childrens raised by wolves tell us a undeniable fact - the high-level cognitive ability is a production of nurture in education. In other words, education is not only a channel to pass on knowledge from one generation to the next, but also a powerful tool to significantly increase individual cognitive ability.\nThe term \u0026ldquo;task system\u0026rdquo; for machines is derived by analogy to education system for humans. However, we do not refer to the exact meaning and content of human education when mentioning task systems for machines, just as we could not teach a dog the way we teach a human. Instead, machine education should be tailored to suit the need of developing machine intelligence.\nA task system should produce a set of tasks, similar in some aspects but different in others. For example, those tasks are set up to solve the same prolem but with different difficulities as in curriculum learning; those tasks face the same prediction goal but with different input domains as in transfer learning. However, lacking a top-level world design, these sort of task setups are not comparable against the real-world ones for humans and even for animals. Therefore, a well-designed task system should be built on a world, a common environment base, which all tasks should use the materials of as their design elements and also be consistent with. This world does not have to be exactly identical to our real world. However, the world should be able to grow with new elements and details added, so that new tasks could be continuously generated from it.\nFor the learning purpose, there is a more profound goal for machines than simply learning to solve one specific task, which is to estabilish a deep and full understanding of how the world works through attempting to solve tasks one after another. I list several types of tasks as follows:\n Predicting unseen states or things in the world based on partial observation. Machines need to develop this kind of ability to break the barrier of time and space, and also overcome the limitatin of its own body such as sensors. Causal reasoning about the inner workings of the world such as the physical laws. Machines should be aware of the possible consequences of each action as well as an occuring event by watching real scenarios, imagining counterfactual scenarios and intervening in the world. This ability will help machines develop its own mental environment model to mimick and interpret the world it lives in. Planning. Based on the environment model developed by causal reasoning, machines should be able to do planning and navigate itself in the action space to finish a relatively complex job. Communicating and collaborating with other machines. Intelligence emergence is a production of a society rather than a single individual. Developing a set of abstract symbols with some syntax within a society to boost the intelligence level of the entire society. This is the ability of acquiring languages, including assigning a symbol a specific meaning, using more symbols syntactically to capture or constuct more complex meaning, understanding symbols generated by other machines, and knowing how to behave under the guidence of symbols. Continously developing abstract symbols into a more adavanced language system. Ultimately, machines own the ability to write novels, summerize life experiences, and develop their own strategy and philosophy individually and globally.  ",
    "date": 1541952000,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1541952000,
    "objectID": "d32d972a3c340df1538634042492e2a0",
    "permalink": "https://www.xiaoranxu.com/thinking/about-task-systems/",
    "publishdate": "2018-11-12T00:00:00+08:00",
    "relpermalink": "/thinking/about-task-systems/",
    "section": "thinking",
    "summary": "AI needs deliberately designed education. Current machine learning and deep learning models are trained by tasks that come mostly from real-life applications with practical purposes. Few tasks are designed specially and systematically for the purpose of studying pure intelligence. Why is this very important? Much efforts today in the AI community have been put on designing AI models that are AI's brains, whereas less studies are concentrated on how to design and organize a series of tasks that can help AI grow ...",
    "tags": [
      "Machine Education, Growing AI"
    ],
    "title": "Task System for machines V.S. Education System for Humans",
    "type": "thinking"
  },
  {
    "authors": [
      "Xiaoran Xu"
    ],
    "categories": null,
    "content": "Each time I attempt to see intelligence in machine learning models, there would be a doubt rising in my head - how could intelligence, characterized by high-level abstraction capability, be acquired simply by a gradient descent process reaching convergence? I would rather believe that the journey of pursuing intelligence is a back-and-forth, twist-and-turns, and chaotic-and-conscious process with loops, eventually jumping out of loops and reaching some enlightment point. Therefore, it cannot be achieved only with one single objective formulated by one specific optimizatoin problem.\nIf you begin to question that, you might find the root of the problem lies in our research motivation for studying AI. Many people would think that the subject of AI research should be a concrete application-oriented problem, but I would rather believe the intelligence itself should be laid at the core of the subject we should study. If we wish to solve almost everything using intelligence, how could it be possible to achieve it bypassing intelligence. Even if we may not know what exact properties artificial intelligence should have, at least we could find some clues from ourselves - human intelligence.\nFrom this perspective, I acquired some inspiration from children learning to propose a hypothesis of a continuous self-training framework - a continuous process alternating between finding a puzzle and solving a puzzle. As we were children, we explored the world mainly out of curiosity. This process can be decomposed into three questions:\n Is it easy to find or construct a puzzle by the child or the agent? Is this puzzle likely to be solved by the child or the agent? How much sense of achievement is gained from solving a puzzle by the child or the agent?  I take a specific scenario that children love watching cartoons more than movies. It is obvious that cartoons have a lot of non-realistic scenes, such as bright colors with high contrast and talking animals. We must notice that the lack of fidelity does not affect children\u0026rsquo;s cognition at all. On the contrary, children may be sensitive to the cognition complexity required in a scene. Bright colors catch children\u0026rsquo;s eyes because they help kids to distiguish objects from one another in their field of vision. Talking animals appeal to children because children may find it easier to understand anthropomorphic characters by animal appearances than to understand human psychology and behavior. Therefore, children\u0026rsquo;s cognition progressing needs incentive built properly as a driving engine to keep them focusing and learning autonomously, implicitly or explicitly, which I call continuous self-training.\nThe scenario fits the above three-questions schema in the finding-solving framework. First, would it be easy for children to form a puzzle in their heads by watching cartoons. An obvious fact is that children prefer reading pictures to reading texts, and prefer reading cartoon pictures to reading real-world images. A cartoon character with a strange shape or a dumb movement, such as a banana-like head or a falling-down movement, tends to create a cognitively simple but surprising event and draw children\u0026rsquo;s attention, forming a puzzle more easily. By watching cartoons, a small rudimentary environment model would develop in children\u0026rsquo;s heads, often with a narrative storyline made up from the children\u0026rsquo;s point of view, which always goes with a series of WHY questions to seek explanations. I think this is where children begin to acquire the basic causal reasoning capability. Although adults might see these questions either having obvious answers or being meaningless to ask, for children such questions constitute initial puzzles to help develop their common knowledge.\nAfter forming a puzzle, we will assess whether the puzzle is easy to solve and might try multiple times harder and harder. If we solve it, the degree of being able to acquire new knowledge will contribute to the sense of reward. Little knowledge acquired might make us feel boring, whereas much new knowledge gained tends to cause us to feel satisified and even excited. If we fail to solve it after many attempts, we may give it up without any reward obtained but being exhausted. Often, we would first consider whether it is worth solving based on our previous experience, by evaluting how likely we are able to solve it and how much reward it can bring us. For children, their sense of reward may be mainly driven by their curiosity and possible acheivement they might get. As they grow up, answering such simple questions cannot bring them new knowledge and experience any more, leading to little reward. They need to find new puzzles and solve them.\nThe process of finding, evaluating, tring to solve, failing or succeeding, getting rewarded or not, and then re-evluating, happens so quickly that we might not be aware of how we are motivated in our everyday life. When we become adults, the reward expectation system becomes so complex that the curiosity and knowledge achievement are not the only inccentives to drive us. As our environment models become strong, we are able to do long-term planning and get self-motivated by some ultimate goal we call the life purpose.\nI know this is a big topic beyond our current techniques pursuing AI, but we can still apply this thinking to some computation models such as GANs. In this adversarial training framework, the two opponent roles can be simultaneously hosted in our brain, one to propose a puzzle, one to solve it. The puzzle is proposed by the discriminator and left for the generator to solve. To find the most rewarding puzzle, the discriminator has to play in an adversarial style, that is, to pick the biggest weakness in the generator leading to a large margin to progress. Some troubles in training GANs can be also explained using this framework. Sometimes, the generator fails to solve puzzles given by the discriminator, getting stuck in a poor finding-solving process.\nFor future work, we need to figure out more computation framework to reflect the finding-solving process besides GANs.\n",
    "date": 1541865600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1541865600,
    "objectID": "5d7cf0defd19cef22856c3bc71ee9463",
    "permalink": "https://www.xiaoranxu.com/thinking/about-objectives/",
    "publishdate": "2018-11-11T00:00:00+08:00",
    "relpermalink": "/thinking/about-objectives/",
    "section": "thinking",
    "summary": "How are we motivated to do continuous self-training? Each time I attempt to see intelligence in machine learning models, there would be a doubt rising in my head - how could intelligence, characterized by high-level abstraction capability, be acquired simply by a gradient descent process reaching convergence? I would rather believe that the journey of pursuing intelligence is a back-and-forth, twist-and-turns, and chaotic-and-conscious process with loops, eventually jumping out of loops and reaching some enlightment point. Therefore, it cannot be achieved only with one single objective formulated by one specific optimizatoin problem. Then, I acquired some inspiration from children learning to propose a hypothesis of a continuous self-training framework - a continuous process alternating between finding a puzzle and solving a puzzle ...",
    "tags": [
      "Continous Self-Training"
    ],
    "title": "Objective Functions V.S. Life Purposes",
    "type": "thinking"
  },
  {
    "authors": [
      "Xiaoran Xu"
    ],
    "categories": null,
    "content": "There are two major theories of the brain\u0026rsquo;s cognitive function - the theory of modularity and the theory of distributive processing. Instead of asking whether brain\u0026rsquo;s regions are functionally interconnected or specialized, I tend to think of them as complementary to each other.\nFor the modularity theory, specialized regions are domain specific for different cognitive processes. From the evolutionary perspective, human mind evolved with enhanced functionality developing as a result of its increasing fitting capability to gain more adaptiveness, such as prefrontal cortex that handles high-level cognitive processes, and visual area V4 and V5 in charge of the perception of color and vision motion.\nFor distributive processing, brain areas are highly interconnected and process information in a distributed manner. Thanks to advances of brain imaging techniques such as MRI and PET scans, neural interactions can be measured by analysis in neuroimaging, which provides more evidence to support the interaction theory of distributive processing. Many regions in the brain are physically interconnected in a nonlinear system, procuding behaviors as a result of a variety of system organizations.\nThe two theories should be combined to collaboratively characterize the functioning of the brain. Modularity is a matter of degree rather than a rigid separation, and the nervous system always integrates information produced in different regions.\nOne of the biggest breakthroughs for artificial neural networks is to realize the importance of the idea of distributive representation that brings powerful expressivity. The specific meaning for each individual neuron unit is not neccessary, but instead the space spanned by a set of peer units may carry a semantically meaningful manifold, sort of a collective production.\nHowever, the specialization property has not been well taken into account. Considering a fully-connected layer, each unit has access to its previous and next layers, receiving signals from all units in the previous layer and sending signals to all units in the next layer. There is no any specialization for each unit, since every unit has a similar role to one another. The only difference between each peer unit is their weights of connections to the two adjacent layers. Relying on such level of difference, one cannot expect that some sort of specialization and modularity would emerge. Of course, scalar units hold too limited information to carry subspace-level semantics and develop their specialization, and thus we should consider multi-dimension neuron unit or neuron node consisting of multiple atomic units to build a big neuron-node network. From this point of view, a standard DNN would turn into a chain computation architecture by wrapping units of each layer into a neuron node, without any branch or bypass. Therefore, each time we run a forward pass, every node would be activated and then updated regardless of whether it should be or not. I guess the chain architecture may be one of the factors that cause catastrophic forgetting or the interference problem.\nI tend to think of a multi-way graph-structured architecture instead of a single-way chain-structured architecture, with branching or mergining possibly occuring at any point, which can be seen as an ultimate exention to skip connections, lateral connections and highway. We can image a gaint high-dimensional mesh net with some fractal structure, that it, with local-scale structures that hold unforgetable details as well as global-scale structures that enable regions to interacte with one another and exchange information efficently. Moreover, this gaint mesh net will not be operated fully, but instead only a small fraction of nodes will be actived to interact, forming a small subgraph performing computation.\nA quetion is raised in the this computation framework - how do we pick the actived subgraph out of the gaint mesh net? And what does it stand for?\nIt actually implies a navigation problem that requires choosing nodes and edges at each step, a type of actions that happens in the computation graph. From a low-level computation view, it navigates computation flow through a subgraph of the big neural-node network; from a high-level concept view, a graph-structured architecture may be a better way to encode the external environment into an internal environment model, the imagination world, so that a couterfactual experiment could be conducted in this world by taking virtual actions through an imaginary adventure. Couterfactual reasoning and action intervention are key factors to develop causal cognition for humans.\nFinally, I would take a bold move to speculate that it is attention that causes our consciouness flow. On the one hand, there is an attention mechanism in the computation framework level to draw out a subgraph and navigate the computation flow; on the other hand, attention can be viewed as a mental action, consciously navigating us in our conceptual or imagination world.\nThere is an old saying, one of the principles in Chinese Tai Chi martial art - \u0026ldquo;Use Yi (use wish), don\u0026rsquo;t use Li (apply force)\u0026rdquo;.\n",
    "date": 1541779200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1541779200,
    "objectID": "9c713f5295f55d2ddde9b44094e5d6c5",
    "permalink": "https://www.xiaoranxu.com/thinking/about-architectures/",
    "publishdate": "2018-11-10T00:00:00+08:00",
    "relpermalink": "/thinking/about-architectures/",
    "section": "thinking",
    "summary": "Two theories collaboratively characterize the brain functioning - modularity and distributive processing. One of the keys to the success of artificial neural networks is the idea of distributive representation. However, the modularity and specialization property has not been well taken into account. I tend to think of a multi-way graph-structured architecture, with branching or mergining possibly at any point, an ultimate exention to skip connections, lateral connections and highway. Moreover, this gaint net would not be operated fully, but only a small fraction would be actived to form a computation subgraph. This implies a navigation problem that requires choosing nodes and edges at each step, a type of actions that happens in the computation graph. Finally, the computation graph may form a high-level conceptual or imagination world. I speculate that it might be attention that causes our consciouness flow. On the one hand, there must be an attention mechanism to draw out a subgraph and navigate the computation flow; on the other hand, attention can be seen as a mental action, consciously navigating us in our imagination world ...",
    "tags": [
      "Brain Architecture"
    ],
    "title": "Artificial Neural Nets V.S. Human Brain Nets",
    "type": "thinking"
  },
  {
    "authors": [
      "Xiaoran Xu",
      "Songpeng Zu",
      "Chengliang Gao",
      "Yuan Zhang",
      "Wei Feng"
    ],
    "categories": null,
    "content": "",
    "date": 1541062794,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1541062794,
    "objectID": "1f1f2d6d5b248b30f9beb9580bc61712",
    "permalink": "https://www.xiaoranxu.com/publication/modeling-attflow/",
    "publishdate": "2018-11-01T16:59:54+08:00",
    "relpermalink": "/publication/modeling-attflow/",
    "section": "publication",
    "summary": "Real-world scenarios demand reasoning about process, more than final outcome prediction, to discover latent causal chains and better understand complex systems. It requires the learning algorithms to offer both accurate predictions and clear interpretations. We design a set of trajectory reasoning tasks on graphs with only the source and the destination observed. We present the attention flow mechanism to explicitly model the reasoning process, leveraging the relational inductive biases by basing our models on graph networks. We study the way attention flow can effectively act on the underlying information flow implemented by message passing. Experiments demonstrate that the attention flow driven by and interacting with graph networks can provide higher accuracy in prediction and better interpretation for trajectories reasoning.",
    "tags": [
      "Attention Flow",
      "Causal Chains",
      "Graph Networks",
      "Random Walk",
      "Reasoning"
    ],
    "title": "Modeling Attention Flow on Graphs",
    "type": "publication"
  },
  {
    "authors": [
      "Xiaoran Xu",
      "Laming Chen",
      "Songpeng Zu",
      "Hanning Zhou"
    ],
    "categories": null,
    "content": "",
    "date": 1537977600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1537977600,
    "objectID": "1d5e0e80307304e62024a295ab2bb3e6",
    "permalink": "https://www.xiaoranxu.com/publication/hulu-video-reco/",
    "publishdate": "2018-09-27T00:00:00+08:00",
    "relpermalink": "/publication/hulu-video-reco/",
    "section": "publication",
    "summary": "Online Video Streaming services such as Hulu hosts tens of millions of premium videos, which requires an effective recommendation system to help viewers discover what they enjoy. In this talk, we will introduce Hulu's recent technical progresses in recommender systems and deep-dive into the topic of generating recommendation reason from knowledge graph. We have two user scenarios: the store-shelf and autoplay. The first requires a list of videos to maximize the chance that a viewer would pick one of them to watch. The second requires a sequence of video recommendations such that the viewer would continuously watch within the current session.\n\nIn the model layer, we designed specific models to match with each user scenario, balancing both exploitation and exploration. For example, we leverage the contextual-bandit model in the store-shelf scenario to adapt the ranking strategy to various types of user feedbacks. To optimize exploitation, we tested several granularity levels for parameter sharing among the arms. For more effective exploration, we incorporate Thomason sampling. For the autoplay scenario, we use a contextual recurrent neural network to predict the next video that the viewer is going to watch.\n\nIn the feature and data layer, we train embeddings for content, user and contextual info. For example, to train content embeddings, we collect factual tags from metadata, sentiment tags from reviews, and keywords from the captions and object/action recognized using computer vision techniques.\n\nNext we will deep-dive into one important topic: generating recommendation reason from knowledge graph.\n\nA fact is defined by a tuple of related entities and their relation, which is normally a pair of entities tagged by a relationship. In our problem setting, recommendation results are the targets, viewed as inputs for the reasoning task, consisting of pairs of relevant entities, i.e. a source node and a destination node in a knowledge graph. The recommendation reasoning task is to learn a path or a small directed acyclic subgraph, connecting the source node to the destination node.\n\nSince the facts in a knowledge graph have different confidence values for different reasoned targets, we need to conduct a probabilistic inference. The challenge is we do not know a predefined set of logic rules to guide the search through the knowledge graph, which prevents us from directly applying the probabilistic logic methods. Inspired by recent advances in deep learning and reinforcement learning, especially in graph neural networks, attention mechanism and deep generative models, we propose two ways to model the reasoning process: the differentiable reasoning approach and the stochastic reasoning approach.\n\nDifferentiable reasoning approaches are based on graph neural networks [1,2] with attention flow and information flow. The attention dynamics is an iterative process of redistributing and aggregating attention over the knowledge graph, starting at the source node. The final attention aggregated at the destination node serves for the prediction to compute the loss. Instead of the prediction accuracy, we care more about how the learned attention dynamics draws its reasoning track in a knowledge graph.\n\nStochastic reasoning approaches frame the reasoning process as learning a probabilistic graphical model consisting of stochastic discrete operations, such as selecting a node and selecting an edge, to build a reason subgraph extracted from the knowledge graph. The model is known as stochastic computation graphs (SCGs), and to learn it, we propose a generalized back-propagation framework Backprop-Q [3] to overcome the gradient-blocking issues in applying standard back-propagation. In summary, we give an overview of the recommendation research in Hulu and deep-dive into our differentiable reasoning approach and stochastic reasoning approach for generating recommendation reasons based on a knowledge graph.",
    "tags": [],
    "title": "Hulu video recommendation: from relevance to reasoning",
    "type": "publication"
  },
  {
    "authors": null,
    "categories": null,
    "content": " In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n",
    "date": 1536422400,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1536422400,
    "objectID": "6a451186c775f5f0adb3a0416d0cb711",
    "permalink": "https://www.xiaoranxu.com/tutorial/example/",
    "publishdate": "2018-09-09T00:00:00+08:00",
    "relpermalink": "/tutorial/example/",
    "section": "tutorial",
    "summary": "In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;",
    "tags": null,
    "title": "Example Page",
    "type": "docs"
  },
  {
    "authors": [
      "Yuan Zhang",
      "Xiaoran Xu",
      "Hanning Zhou",
      "Yan Zhang"
    ],
    "categories": null,
    "content": "",
    "date": 1535299200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1535299200,
    "objectID": "a99eff11fa30c50fb00719f332eb2c12",
    "permalink": "https://www.xiaoranxu.com/publication/distilling-structured-knowledge/",
    "publishdate": "2018-08-27T00:00:00+08:00",
    "relpermalink": "/publication/distilling-structured-knowledge/",
    "section": "publication",
    "summary": "Recently, the embedding-based recommendation models (e.g., matrix factorization and deep models) are prevalent in both academia and industry due to their effectiveness and flexibility. However, they also have such intrinsic limitations as lacking explainability and suffering from data sparsity. In this paper, we propose an end-to-end joint learning framework to get around these limitations without introducing any extra overhead by distilling structured knowledge from a differentiable path-based recommendation model. Through extensive experiments, we show that our proposed framework can achieve state-of-the-art recommendation performance and meanwhile provide well interpretable recommendation reasons.",
    "tags": [
      "Explainable Recommendation",
      "Knowledge Distillation",
      "Differentiable Path-based Model"
    ],
    "title": "Distilling Structured Knowledge into Embeddings for Explainable and Accurate Recommendation",
    "type": "publication"
  },
  {
    "authors": [
      "Xiaoran Xu",
      "Songpeng Zu",
      "Yuan Zhang",
      "Hanning Zhou",
      "Wei Feng"
    ],
    "categories": null,
    "content": "",
    "date": 1532484384,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1532484384,
    "objectID": "54f07db9336d701e66d9f1c1695cb427",
    "permalink": "https://www.xiaoranxu.com/publication/backprop-q/",
    "publishdate": "2018-07-25T10:06:24+08:00",
    "relpermalink": "/publication/backprop-q/",
    "section": "publication",
    "summary": "In real-world scenarios, it is appealing to learn a model carrying out stochastic operations internally, known as stochastic computation graphs (SCGs), rather than learning a deterministic mapping. However, standard backpropagation is not applicable to SCGs. We attempt to address this issue from the angle of cost propagation, with local surrogate costs, called Q-functions, constructed and learned for each stochastic node in an SCG. Then, the SCG can be trained based on these surrogate costs using standard backpropagation. We propose the entire framework as a solution to generalize backpropagation for SCGs, which resembles an actor-critic architecture but based on a graph. For broad applicability, we study a variety of SCG structures from one cost to multiple costs. We utilize recent advances in reinforcement learning (RL) and variational Bayes (VB), such as off-policy critic learning and unbiased-and-low-variance gradient estimation, and review them in the context of SCGs. The generalized backpropagation extends transported learning signals beyond gradients between stochastic nodes while preserving the benefit of backpropagating gradients through deterministic nodes. Experimental suggestions and concerns are listed to help design and test any specific model using this framework.",
    "tags": [
      "Backpropagation",
      "Credit Assignment",
      "Stochastic Computation Graphs"
    ],
    "title": "Backprop-Q: Generalized Backpropagation for Stochastic Computation Graphs",
    "type": "publication"
  },
  {
    "authors": null,
    "categories": null,
    "content": " Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n",
    "date": -62135596800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": -62135596800,
    "objectID": "c2915ec5da95791851caafdcba9664af",
    "permalink": "https://www.xiaoranxu.com/slides/example-slides/",
    "publishdate": "0001-01-01T00:00:00Z",
    "relpermalink": "/slides/example-slides/",
    "section": "slides",
    "summary": "Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$",
    "tags": null,
    "title": "Slides",
    "type": "slides"
  }
]